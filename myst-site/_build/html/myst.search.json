{"version":"1","records":[{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/k-means","position":0},{"hierarchy":{"lvl1":""},"content":"print(\"hello-world\")","type":"content","url":"/k-means","position":1},{"hierarchy":{"lvl1":"Machine Learning Guide"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Machine Learning Guide"},"content":"Welcome to the Machine Learning Guide! This resource is designed to help you understand machine learning concepts, from basic models to advanced neural networks and natural language processing (NLP) tasks. This guide follows an Occam’s razor approach, starting with simpler models and gradually progressing to more complex ones. Each topic includes theoretical explanations, code examples, and data visualizations.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl2":"Table of Contents"},"type":"lvl2","url":"/#table-of-contents","position":2},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl2":"Table of Contents"},"content":"","type":"content","url":"/#table-of-contents","position":3},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"1. Introduction to Machine Learning","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-1-introduction-to-machine-learning","position":4},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"1. Introduction to Machine Learning","lvl2":"Table of Contents"},"content":"What is Machine Learning?: Overview of machine learning concepts, definitions, and applications.\n\nTypes of Machine Learning: Supervised, unsupervised, semi-supervised, and reinforcement learning.\n\nOccam’s Razor in Machine Learning: Importance of simplicity in model selection and avoiding overfitting.","type":"content","url":"/#id-1-introduction-to-machine-learning","position":5},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"2. Basic Statistics and Data Exploration","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-2-basic-statistics-and-data-exploration","position":6},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"2. Basic Statistics and Data Exploration","lvl2":"Table of Contents"},"content":"Descriptive Statistics: Mean, median, mode, variance, standard deviation. Data visualization: histograms, box plots, and scatter plots.\n\nData Distribution: Understanding normal distribution, skewness, kurtosis. Visualizing data distribution with histograms and Q-Q plots.\n\nCorrelation and Covariance: Understanding relationships between variables. Visualizing relationships with heatmaps and pair plots.","type":"content","url":"/#id-2-basic-statistics-and-data-exploration","position":7},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"3. Data Preprocessing and Feature Engineering","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-3-data-preprocessing-and-feature-engineering","position":8},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"3. Data Preprocessing and Feature Engineering","lvl2":"Table of Contents"},"content":"Handling Missing Values: Techniques such as mean/mode imputation, KNN imputation.\n\nFeature Scaling and Normalization: Standardization, min-max scaling, and log transformation.\n\nCategorical Data Encoding: One-hot encoding, label encoding, and target encoding.\n\nFeature Selection Techniques: Techniques like correlation analysis, chi-square test, and LASSO for selecting relevant features.","type":"content","url":"/#id-3-data-preprocessing-and-feature-engineering","position":9},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"4. Simple Models and Baselines","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-4-simple-models-and-baselines","position":10},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"4. Simple Models and Baselines","lvl2":"Table of Contents"},"content":"Mean and Median as Predictors: Using simple baselines for regression and classification tasks.\n\nLinear Regression: Theory, assumptions, and interpretation. Includes predicting house prices with visualization of residual plots and coefficients.\n\nLogistic Regression: Theory of logistic regression, sigmoid function, and decision boundary. Titanic dataset classification project with ROC curves and confusion matrices.","type":"content","url":"/#id-4-simple-models-and-baselines","position":11},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"5. Decision Trees and Ensemble Methods","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-5-decision-trees-and-ensemble-methods","position":12},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"5. Decision Trees and Ensemble Methods","lvl2":"Table of Contents"},"content":"Decision Trees: Theory of decision trees, including Gini impurity and information gain. Classifying the Iris dataset with visualization of decision tree plots.\n\nRandom Forests: Bagging, out-of-bag error, and feature importance. Classifying wine quality with feature importance and error plots.\n\nGradient Boosting and XGBoost: Boosting techniques, learning rate, and regularization. Predicting Boston housing prices with SHAP plots and feature interactions.","type":"content","url":"/#id-5-decision-trees-and-ensemble-methods","position":13},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"6. Support Vector Machines (SVM)","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-6-support-vector-machines-svm","position":14},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"6. Support Vector Machines (SVM)","lvl2":"Table of Contents"},"content":"Linear SVM: Understanding hyperplanes and margin maximization. Binary classification with visualization of decision boundaries and support vectors.\n\nKernel SVM: Theory of kernel functions for non-linear decision boundaries. Classifying non-linear data with different kernel functions.","type":"content","url":"/#id-6-support-vector-machines-svm","position":15},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"7. Clustering and Dimensionality Reduction","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-7-clustering-and-dimensionality-reduction","position":16},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"7. Clustering and Dimensionality Reduction","lvl2":"Table of Contents"},"content":"K-Means Clustering: Centroid-based clustering, inertia, and the elbow method. Customer segmentation with cluster plots and silhouette score.\n\nHierarchical Clustering: Theory of dendrograms and linkage methods. Visualizing hierarchical clusters with dendrogram plots and heatmaps.\n\nPrincipal Component Analysis (PCA): Dimensionality reduction and variance explanation. Visualizing high-dimensional data with explained variance plots and PCA plots.","type":"content","url":"/#id-7-clustering-and-dimensionality-reduction","position":17},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"8. Advanced Regression Techniques","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-8-advanced-regression-techniques","position":18},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"8. Advanced Regression Techniques","lvl2":"Table of Contents"},"content":"Ridge and Lasso Regression: Regularization techniques and bias-variance tradeoff. Predicting real estate prices with coefficient paths and error plots.\n\nPolynomial Regression: Modeling non-linear relationships. Visualization of curve fitting and residual plots.","type":"content","url":"/#id-8-advanced-regression-techniques","position":19},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"9. Neural Networks and Deep Learning","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-9-neural-networks-and-deep-learning","position":20},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"9. Neural Networks and Deep Learning","lvl2":"Table of Contents"},"content":"Multilayer Perceptron (MLP): Understanding perceptrons, activation functions, and backpropagation. Handwritten digit classification (MNIST) with loss curves and accuracy plots.\n\nConvolutional Neural Networks (CNN): Convolutional layers, pooling, and feature maps. Image classification (CIFAR-10) with feature map visualization and filter visualization.\n\nRecurrent Neural Networks (RNN) and LSTMs: Sequence modeling, vanishing gradient problem, and LSTMs. Sentiment analysis on text data with RNN activations and attention plots.","type":"content","url":"/#id-9-neural-networks-and-deep-learning","position":21},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"10. Natural Language Processing (NLP)","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-10-natural-language-processing-nlp","position":22},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"10. Natural Language Processing (NLP)","lvl2":"Table of Contents"},"content":"Text Preprocessing: Techniques like tokenization, stemming, lemmatization, and stop-word removal.\n\nWord Embeddings: Understanding Word2Vec, GloVe, and contextual embeddings. Word similarity and analogy tasks.\n\nText Classification and Sentiment Analysis: Bag-of-words, TF-IDF, and LSTM for text classification. Sentiment analysis on movie reviews with word clouds and confusion matrices.","type":"content","url":"/#id-10-natural-language-processing-nlp","position":23},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"11. Advanced Topics and Special Cases","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-11-advanced-topics-and-special-cases","position":24},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"11. Advanced Topics and Special Cases","lvl2":"Table of Contents"},"content":"Generative Adversarial Networks (GANs): Theory of GANs, generator and discriminator models. Image generation on MNIST dataset with visualization of generated images.\n\nTransfer Learning: Using pre-trained models and fine-tuning. Image classification with ResNet and visualization of feature maps.\n\nReinforcement Learning: Markov Decision Processes, Q-learning, and policy gradients. Solving OpenAI Gym environments with reward plots and action distributions.","type":"content","url":"/#id-11-advanced-topics-and-special-cases","position":25},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"12. Model Evaluation and Interpretability","lvl2":"Table of Contents"},"type":"lvl3","url":"/#id-12-model-evaluation-and-interpretability","position":26},{"hierarchy":{"lvl1":"Machine Learning Guide","lvl3":"12. Model Evaluation and Interpretability","lvl2":"Table of Contents"},"content":"Model Evaluation Metrics: Metrics like accuracy, precision, recall, F1 score, ROC-AUC, MAE, and RMSE.\n\nCross-Validation and Hyperparameter Tuning: k-fold cross-validation, grid search, and random search. Hyperparameter tuning for Random Forests with validation curves and grid search results.\n\nModel Interpretability Techniques: LIME, SHAP, and partial dependence plots. Interpret a complex model (XGBoost) on the Titanic dataset with SHAP plots and feature importance.\n\nExplore the guide by navigating through the sections above. Each topic contains both theoretical explanations and practical code examples to help you get hands-on experience with machine learning concepts.","type":"content","url":"/#id-12-model-evaluation-and-interpretability","position":27},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/intro-to-ml","position":0},{"hierarchy":{"lvl1":""},"content":"print(\"hello world\")","type":"content","url":"/intro-to-ml","position":1},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/types-of-ml","position":0},{"hierarchy":{"lvl1":""},"content":"print(\"heh\")","type":"content","url":"/types-of-ml","position":1}]}